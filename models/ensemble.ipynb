{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ensemble","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyNwwG9vQsjh4YeN37OvPDUM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"ZaBczuITOwz8","colab_type":"code","colab":{}},"source":["# function ClickConnect() {\n","#   console.log('Working')\n","#   document\n","#     .querySelector('#top-toolbar > colab-connect-button')\n","#     .shadowRoot.querySelector('#connect')\n","#     .click()\n","# }\n","\n","# setInterval(ClickConnect, 60000)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kX2AyzqEOst_","colab_type":"code","outputId":"1b4cf610-4b61-4458-a116-c10d884f43c1","executionInfo":{"status":"ok","timestamp":1591722836074,"user_tz":-120,"elapsed":181801,"user":{"displayName":"Max Joosten","photoUrl":"","userId":"12353708236585624489"}},"colab":{"base_uri":"https://localhost:8080/","height":83}},"source":["%%time\n","# Colab imports\n","from google.colab import drive\n","\n","# Mount drive\n","drive.mount('/content/gdrive/')\n","\n","# create storage\n","!sudo mkdir -p /content/ramdisk\n","!sudo mount -t tmpfs -o rw,size=6G tmpfs /content/ramdisk\n","\n","# Load drive data to working directory as h5\n","!mkdir /content/ramdisk/ISIC-2017_Training_Data\n","!cp '/content/gdrive/My Drive/BEP_data/all_images.h5' /content/ramdisk/ISIC-2017_Training_Data\n","!cp -R '/content/gdrive/My Drive/crowdskin-bsc-2020/weights' /content/ramdisk/\n","!pip install git+https://github.com/raghakot/keras-vis.git\n","!pip install -U --pre efficientnet"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FqD8SivyO0py","colab_type":"code","outputId":"7297685d-9d95-453d-dc9d-5b749b008cb7","executionInfo":{"status":"ok","timestamp":1591821162250,"user_tz":-120,"elapsed":5220,"user":{"displayName":"Max Joosten","photoUrl":"","userId":"12353708236585624489"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import os\n","# Go to folder in drive\n","os.chdir(\"/content/gdrive/My Drive/crowdskin-bsc-2020/models\")\n","# IMPORTS\n","import keras\n","from generate_data import generate_data_2, Generate_Alt_2\n","from get_data import get_data_2, annototation_type\n","from report_results import report_acc_and_loss, report_auc\n","from sklearn.metrics import roc_auc_score, confusion_matrix\n","import numpy as np\n","from scipy import optimize\n","import os\n","from vis.visualization import visualize_cam\n","from vis.utils import utils\n","import matplotlib.pyplot as plt\n","import efficientnet.keras as efn"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"JXjRF1GCPEmJ","colab_type":"code","outputId":"0feb02b9-a5f0-4b55-d9bf-ffaf712d8c62","executionInfo":{"status":"ok","timestamp":1591822449976,"user_tz":-120,"elapsed":1292934,"user":{"displayName":"Max Joosten","photoUrl":"","userId":"12353708236585624489"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1VLeobRtWzg4aET_SJCuZc3JZaCmlBrMv"}},"source":["# FLAGS\n","# Types are weighted or non_weighted\n","SANITY_CHECK = False\n","VERBOSE = True\n","WEIGHTED = False\n","VISUALISE_CAM = True\n","\n","# Definitions\n","\n","IMAGE_DATA_PATH = '/content/ramdisk/ISIC-2017_Training_Data/'\n","MODEL_PATH = ''\n","REPORT_PATH = '../reports/'\n","WEIGHTS_PATH = '../weights/'\n","TRUTH_CSV = 'ISIC-2017_Training_Part3_GroundTruth.csv'\n","BATCH_SIZE = 20\n","TRUTH_PATH = '../data/'\n","GROUP_PATH = '../data/'\n","# Savename for aucs\n","SAVENAME = 'ensemble_weighted'\n","# Names of saved weights from experiments\n","ReportNames = ['multitask', \"multitask_efficientnet\", \"multitask_inception\", \"multitask_resnet\"]\n","Annotation_Type = annototation_type.asymmetry\n","\n","\n","def read_data(seed, annotation):\n","    global train_id, valid_id, test_id, train_label_c, valid_label_c, test_label_c, train_label_a\n","    global valid_label_a, test_label_a, train_mask, valid_mask, test_mask, class_weights\n","    global train, validation\n","\n","    train_id, valid_id, test_id, train_label_c, valid_label_c, test_label_c, train_label_a, valid_label_a, test_label_a, train_mask, valid_mask, test_mask, class_weights = get_data_2(\n","        GROUP_PATH, TRUTH_PATH, TRUTH_CSV, seed, VERBOSE, SANITY_CHECK, annotation)\n","\n","\n","def load_model(seed, annotation, WeightsPath, ReportName):\n","    # Load model from model type depending on savename for the model and filename end(asymmetry, border or color)\n","    folder_list = os.listdir(WeightsPath)\n","    filtered_reportname = [s for s in folder_list if ReportName in s]\n","    filtered_seed = [s for s in filtered_reportname if str(seed) in s]\n","    filtered_h5 = [s for s in filtered_seed if \"h5\" in s]\n","    filtered_json = [s for s in filtered_seed if \"json\" in s]\n","    try:\n","        if annotation == annotation.asymmetry:\n","            file_json = [s for s in filtered_json if s[-19:-10] == \"asymmetry\"][0]\n","            file_h5 = [s for s in filtered_h5 if s[-17:-8] == \"asymmetry\"][0]\n","            model_type = \"asymmetry\"\n","        if annotation == annotation.border:\n","            file_json = [s for s in filtered_json if s[-16:-10] == \"border\"][0]\n","            file_h5 = [s for s in filtered_h5 if s[-14:-8] == \"border\"][0]\n","            model_type = \"border\"\n","        if annotation == annotation.color:\n","            file_json = [s for s in filtered_json if s[-15:-10] == \"color\"][0]\n","            file_h5 = [s for s in filtered_h5 if s[-13:-8] == \"color\"][0]\n","            model_type = \"color\"\n","    except:\n","        print(\"Not all model files in folder or ReportName incorrect\")\n","        raise\n","    json_file = open(WeightsPath + file_json, 'r')\n","    ModelJSON = json_file.read()\n","    json_file.close()\n","    model = keras.models.model_from_json(ModelJSON)\n","    model.load_weights(WeightsPath + file_h5)\n","    return model, model_type\n","\n","\n","def ensemble_predictions(seeds, ReportName):\n","    # return predictions for a single model in a dictionary for 5 seeds for all annotation (ABC) types\n","    gt_test_dict = {}\n","    predictions_dict_test = {}\n","    gt_val_dict = {}\n","    predictions_dict_val = {}\n","    for seed in seeds:\n","        ann_count = 0\n","        predictions_test = np.zeros([3, 250])\n","        predictions_val = np.zeros([3, 350])\n","        read_data(seed, Annotation_Type)\n","        for a_type in annototation_type:\n","            model, model_type = load_model(seed, a_type, WEIGHTS_PATH, ReportName)\n","            test_gen = generate_data_2(directory=IMAGE_DATA_PATH,\n","                                       augmentation=False,\n","                                       batch_size=20,\n","                                       file_list=test_id,\n","                                       label_1=test_label_c,\n","                                       label_2=test_label_a,\n","                                       sample_weights=test_mask)\n","            val_gen = generate_data_2(directory=IMAGE_DATA_PATH,\n","                                      augmentation=False,\n","                                      batch_size=20,\n","                                      file_list=valid_id,\n","                                      label_1=valid_label_c,\n","                                      label_2=valid_label_a,\n","                                      sample_weights=valid_mask)\n","\n","            model_pred_test = model.predict_generator(test_gen, 13)\n","            delta_size_test = model_pred_test[0].size - test_label_c.count()\n","            predictions_test[ann_count, :] = np.resize(model_pred_test[0], model_pred_test[0].size - delta_size_test)\n","\n","            model_pred_val = model.predict_generator(val_gen, 18)  # Change amount of iterations\n","            delta_size_val = model_pred_val[0].size - valid_label_c.count()\n","            predictions_val[ann_count, :] = np.resize(model_pred_val[0], model_pred_val[0].size - delta_size_val)\n","\n","            if VISUALISE_CAM:\n","                plot_gradCAM(model, test_gen, model_type, seed, ReportName)\n","\n","            if VERBOSE:\n","                print(confusion_matrix(y_pred=test_label_c, y_true=np.rint(predictions_test[ann_count, :])))\n","\n","            ann_count += 1\n","        gt_test_dict[seed] = test_label_c\n","        gt_val_dict[seed] = valid_label_c\n","        predictions_dict_test[seed] = predictions_test\n","        predictions_dict_val[seed] = predictions_val\n","    return gt_test_dict, predictions_dict_test, gt_val_dict, predictions_dict_val\n","\n","\n","def auc_score_ensemble_single(ReportName):\n","    # make ensemble of ABC features of a single model\n","    gt_test_dict, predictions_dict_test, gt_val_dict, predictions_dict_val = reports_dict[ReportName]\n","    for seed in seeds:\n","        gt_test = gt_test_dict[seed]\n","        predictions = predictions_dict_test[seed]\n","        predictions_mean = np.average(predictions, axis=0)\n","        auc = [roc_auc_score(gt_test, predictions_mean)]\n","        report_auc(auc, REPORT_PATH, seed, SAVENAME)\n","\n","\n","def auc_score_ensemble_single_weigthed(ReportName):\n","    # Ensemble model predictions using weight factor optimized on validation set for a single model\n","    gt_test_dict, predictions_dict_test, gt_val_dict, predictions_dict_val = reports_dict[ReportName]\n","    for seed in seeds:\n","        gt_val = gt_val_dict[seed]\n","        predictions_val = predictions_dict_val[seed]\n","        weights = np.array([1 / 3, 1 / 3, 1 / 3])\n","        weigths_min = optimize.minimize(loss_mse,\n","                                        weights,\n","                                        args=(gt_val, predictions_val),\n","                                        method=\"Nelder-Mead\",\n","                                        tol=1e-6,\n","                                        constraints=({'type': 'eq', 'fun': lambda w: 1 - sum(w)}))\n","        gt_test = gt_test_dict[seed]\n","        predictions_test = predictions_dict_test[seed]\n","        predictions_weighted = np.average(predictions_test, weights=weigths_min.x, axis=0)\n","        print(weigths_min.x)\n","        auc = [roc_auc_score(gt_test, predictions_weighted)]\n","        report_auc(auc, REPORT_PATH, seed, SAVENAME)\n","\n","\n","def auc_score_ensemble_multi_ABC():\n","    # Make ensemble of ensemble ensemble of multiple models for abc features per model (Model ensemble)\n","    model_savenames = [\"ensemble_asymmetry\", \"ensemble_border\", \"ensemble_color\"]\n","    for seed in seeds:\n","        predictions_mean = np.zeros([len(annototation_type), 250])\n","        for i in range(len(annototation_type)):\n","            pred_per_model = np.zeros([len(ReportNames), 250])\n","            for ReportNameidx in range(len(ReportNames)):\n","                cur_report = ReportNames[ReportNameidx]\n","                gt_test_dict, predictions_dict_test, gt_val_dict, predictions_dict_val = reports_dict[cur_report]\n","                pred_per_model[ReportNameidx, :] = predictions_dict_test[seed][i]\n","            gt_test = gt_test_dict[seed]\n","            predictions_mean[i, :] = np.average(pred_per_model, axis=0)\n","            auc = [roc_auc_score(gt_test, predictions_mean[i, :])]\n","            report_auc(auc, REPORT_PATH, seed, model_savenames[i])\n","        predictions_all_mean = np.average(predictions_mean, axis=0)\n","        all_auc = [roc_auc_score(gt_test, predictions_all_mean)]\n","        report_auc(all_auc, REPORT_PATH, seed, 'ensemble_all_models')\n","\n","\n","def auc_score_ensemble_multi_ABC_weighted():\n","    # Make ensemble of ensemble ensemble of multiple models for abc features per model (Model ensemble) where results\n","    # are weighted in every ensemble of models (using optimization on validation set)\n","    model_savenames = [\"ensemble_asymmetry\", \"ensemble_border\", \"ensemble_color\"]\n","    for seed in seeds:\n","        predictions_test_mean = np.zeros([len(annototation_type), 250])\n","        predictions_val_mean = np.zeros([len(annototation_type), 350])\n","        for i in range(len(annototation_type)):\n","            pred_test_per_model = np.zeros([len(ReportNames), 250])\n","            pred_val_per_model = np.zeros([len(ReportNames), 350])\n","            for ReportNameidx in range(len(ReportNames)):\n","                cur_report = ReportNames[ReportNameidx]\n","                gt_test_dict, predictions_dict_test, gt_val_dict, predictions_dict_val = reports_dict[cur_report]\n","                pred_test_per_model[ReportNameidx, :] = predictions_dict_test[seed][i]\n","                pred_val_per_model[ReportNameidx, :] = predictions_dict_val[seed][i]\n","            predictions_test_mean[i, :] = np.average(pred_test_per_model, axis=0)\n","            predictions_val_mean[i, :] = np.average(pred_val_per_model, axis=0)\n","        gt_test = gt_test_dict[seed]\n","        gt_val = gt_val_dict[seed]\n","        weights = np.array([1/3, 1/3, 1/3])\n","        weigths_min = optimize.minimize(loss_mse,\n","                                        weights,\n","                                        args=(gt_val, predictions_val_mean),\n","                                        method=\"Nelder-Mead\",\n","                                        tol=1e-6,\n","                                        constraints=({'type': 'eq', 'fun': lambda w: 1 - sum(w)}))\n","        print(weigths_min.x)\n","        predictions_all_mean = np.average(predictions_test_mean, weights=weigths_min.x, axis=0)\n","        all_auc = [roc_auc_score(gt_test, predictions_all_mean)]\n","        report_auc(all_auc, REPORT_PATH, seed, 'ensemble_all_ABC_weighted')\n","\n","\n","def auc_score_ensemble_multi_ABC_model_weighted():\n","    # Make ensemble of ensemble ensemble of multiple models for abc features per model (Model ensemble) where every\n","    # model is weighted before it is ensembled per abc feature (using optimization on validation set)\n","    model_savenames = [\"ensemble_asymmetry_weighted\", \"ensemble_border_weighted\", \"ensemble_color_weighted\"]\n","    for seed in seeds:\n","        predictions_test_mean = np.zeros([len(annototation_type), 250])\n","        for i in range(len(annototation_type)):\n","            pred_test_per_model = np.zeros([len(ReportNames), 250])\n","            pred_val_per_model = np.zeros([len(ReportNames), 350])\n","            for ReportNameidx in range(len(ReportNames)):\n","                cur_report = ReportNames[ReportNameidx]\n","                gt_test_dict, predictions_dict_test, gt_val_dict, predictions_dict_val = reports_dict[cur_report]\n","                pred_test_per_model[ReportNameidx, :] = predictions_dict_test[seed][i]\n","                pred_val_per_model[ReportNameidx, :] = predictions_dict_val[seed][i]\n","            gt_val = gt_val_dict[seed]\n","            gt_test = gt_test_dict[seed]\n","\n","            weights = np.full([len(ReportNames)], fill_value=1/len(ReportNames))\n","            weigths_min = optimize.minimize(loss_mse,\n","                                            weights,\n","                                            args=(gt_val, pred_val_per_model),\n","                                            method=\"Nelder-Mead\",\n","                                            tol=1e-6,\n","                                            constraints=({'type': 'eq', 'fun': lambda w: 1 - sum(w)}))\n","            predictions_test_mean[i, :] = np.average(pred_test_per_model, weights=weigths_min.x, axis=0)\n","            print(weigths_min.x)\n","            auc = [roc_auc_score(gt_test, predictions_test_mean[i, :])]\n","            report_auc(auc, REPORT_PATH, seed, model_savenames[i])\n","\n","        predictions_all_mean = np.average(predictions_test_mean, axis=0)\n","        all_auc = [roc_auc_score(gt_test, predictions_all_mean)]\n","        report_auc(all_auc, REPORT_PATH, seed, 'ensemble_all_model_weighted')\n","\n","\n","def auc_score_ensemble_multi_model():\n","    # Make ensemble of multiple models per abc feature (Feature ensemble)\n","    model_savenames = [\"ensemble_vgg16\", \"ensemble_efficientnetb1\", \"ensemble_inceptionv3\", \"ensemble_resnet50v2\"]\n","    for seed in seeds:\n","        predictions_mean = np.zeros([len(model_savenames), 250])\n","        for ReportName_idx in range(len(ReportNames)):\n","            cur_report = ReportNames[ReportName_idx]\n","            gt_test_dict, predictions_dict_test, gt_val_dict, predictions_dict_val = reports_dict[cur_report]\n","            gt_test = gt_test_dict[seed]\n","            test_predictions = predictions_dict_test[seed]\n","            predictions_mean[ReportName_idx, :] = np.average(test_predictions, axis=0)\n","            auc = [roc_auc_score(gt_test, predictions_mean[ReportName_idx, :])]\n","            report_auc(auc, REPORT_PATH, seed, model_savenames[ReportName_idx])\n","        models_mean = np.average(predictions_mean, axis=0)\n","        auc_all = [roc_auc_score(gt_test, models_mean)]\n","        report_auc(auc_all, REPORT_PATH, seed, 'ensemble_multi_model')\n","\n","\n","def auc_score_ensemble_multi_model_weighted():\n","    # Make ensemble of multiple models per abc feature (Feature ensemble) where the results are weighted per feature\n","    # (using optimization on validation set)\n","    model_savenames = [\"ensemble_vgg16_weighted\", \"ensemble_efficientnetb1_weighted\", \"ensemble_inceptionv3_weighted\", \"ensemble_resnet50v2_weighted\"]\n","    for seed in seeds:\n","        predictions_mean = np.zeros([len(model_savenames), 250])\n","        for ReportName_idx in range(len(ReportNames)):\n","            cur_report = ReportNames[ReportName_idx]\n","            gt_test_dict, predictions_dict_test, gt_val_dict, predictions_dict_val = reports_dict[cur_report]\n","            gt_val = gt_val_dict[seed]\n","            predictions_val = predictions_dict_val[seed]\n","            gt_test = gt_test_dict[seed]\n","            predictions_test = predictions_dict_test[seed]\n","            weights = np.full([len(model_savenames)], fill_value=1/len(model_savenames))\n","            weigths_min = optimize.minimize(loss_mse,\n","                                            weights,\n","                                            args=(gt_val, predictions_val),\n","                                            method=\"Nelder-Mead\",\n","                                            tol=1e-6,\n","                                            constraints=({'type': 'eq', 'fun': lambda w: 1-sum(w)}))\n","            predictions_mean[ReportName_idx, :] = np.average(predictions_test, weights=weigths_min.x, axis=0)\n","            auc = [roc_auc_score(gt_test, predictions_mean[ReportName_idx, :])]\n","            report_auc(auc, REPORT_PATH, seed, model_savenames[ReportName_idx])\n","        models_mean = np.average(predictions_mean, axis=0)\n","        auc_all = [roc_auc_score(gt_test, models_mean)]\n","        report_auc(auc_all, REPORT_PATH, seed, 'ensemble_multi_model_weighted')\n","\n","\n","def loss_mse(weights, gt_val, predictions_val):\n","    predictions = np.average(predictions_val, weights=weights, axis=0)\n","    mse = keras.losses.MeanSquaredError()\n","    loss = mse(gt_val, predictions).numpy()\n","    return loss\n","\n","\n","def plot_gradCAM(model, test_gen, model_type, seed, ReportName):\n","    # plot a Gradient-weighted Class Activation Mapping of the test images.\n","    last_layer = utils.find_layer_idx(model, \"out_class\")\n","    batch = next(test_gen)\n","    number_in_batch = np.argwhere(batch[1]['out_class'] < 0.5)[5][0]\n","    # print(number_in_batch) # Debug\n","    image = batch[0][number_in_batch]\n","    GT = batch[1]['out_class'][number_in_batch]\n","    print(batch[1]['out_class'])\n","    prediction = model.predict(np.expand_dims(image, axis=0))[0][0][0]\n","    if ReportName != \"multitask_inception\":\n","        CAM_image = visualize_cam(model=model, layer_idx=last_layer, seed_input=image, filter_indices=None)\n","    else:\n","        CAM_image = visualize_cam(model=model, layer_idx=last_layer, penultimate_layer_idx=310,\n","                                  seed_input=image, filter_indices=None)\n","    fig, axes = plt.subplots(1, 2)\n","    axes[0].imshow(image)\n","    axes[1].imshow(image)\n","    axes[1].imshow(CAM_image, alpha=0.5, cmap='jet')\n","    if ReportName == 'multitask':\n","        ReportName = 'VGG16'\n","    if ReportName == 'multitask_efficientnet':\n","        ReportName = 'EfficientNetB1'\n","    if ReportName == 'multitask_inception':\n","        ReportName = 'InceptionV3'\n","    if ReportName == 'multitask_resnet':\n","        ReportName = 'ResNet'\n","    plt.suptitle('Model: ' + ReportName + ', Model type: ' + model_type + ', Prediction: ' + str(round(prediction, 2)) + ', Ground truth: ' + str(\n","        GT))# + ', Seed: ' + str(seed))\n","    axes[1].set_title('Gradient-CAM of Test image')\n","    axes[0].set_title('Test image')\n","    axes[1].axis('off')\n","    axes[0].axis('off')\n","    plt.savefig('/content/gdrive/My Drive/crowdskin-bsc-2020/Visualisation and misc/' + ReportName + '_' + str(seed) + '_' + model_type + '.svg')\n","    plt.show()\n","\n","\n","seeds = [1970, 1972, 2008, 2019, 2020]\n","reports_dict = dict()\n","for ReportName in ReportNames:\n","    gt_test_dict, predictions_dict_test, gt_val_dict, predictions_dict_val = ensemble_predictions(seeds, ReportName)\n","    reports_dict[ReportName] = [gt_test_dict, predictions_dict_test, gt_val_dict, predictions_dict_val]\n","# auc_score_ensemble_multi_ABC()\n","\n"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}